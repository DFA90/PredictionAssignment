---
title: "MachineLearning"
author: "DAF"
date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: hide
    number_sections: yes
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: no
    hide: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(plyr)
library(dplyr)
library(ggplot2)
library(caret)

# set.seed(62433)
```

#Preprocessing

## Download files
```{r, cache=T}
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "fitTrain.csv")
training = read.csv("fitTrain.csv")

download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "fitTest.csv")
testing = read.csv("fitTest.csv")
```

## Split Data for Cross Validation
To test our modelfits we split up (70:30) our training set to apply cross-validation.
```{r}
inTrain <- createDataPartition(y = training$classe, p = 0.7, list = F)
trainingTrain <- training[inTrain,]
trainingTest <- training[-inTrain,]
```


## Cleanup data
Some columns provided have to be removed. For example the name of the testpersons as well the the time can't be used to predict for a random person at a random time. Furthermore some columns might contain at least 80% NA. These data isn't reliable and therefore is removed.
```{r cleanup}
trainNoTime <- trainingTrain[,-c(1:7)] #remove inapprpriate columns

na80 <- apply(trainNoTime, 2, function(i){mean(is.na(i)) > 0.8}) %>% as.vector() #find + remove > 80% NA
trainNA <- trainNoTime[, !na80]
```

Further preprocessing is done automatically by *preProcess*. First remove columns with variance close to zero (*nzv*), then apply *center*, *scale* and *pca*.
```{r preProcess}
(preProc <- preProcess(trainNA[,-ncol(trainNA)], method = c("center", "scale", "nzv", "pca"), thresh = 0.90))
```

Apply preprossing to training set. Use only new features from preprocessing!
```{r trainTraining}
trainPC <- predict(preProc, trainNA)[,34:(34+preProc$numComp)]
```

## Modelfits
After training the models we apply them to  the remaining data from the trainig data to get an idea of the accuracy.

### Random Forest
The first attempt is *random forest*. 
```{r rf, cache=T}
(modelfit1 <-train(classe ~., data = trainPC, method = "rf"))
pred1 <- predict(modelfit1, predict(preProc, trainingTest))
confusionMatrix(pred1, trainingTest$classe)
```

```{r gbm, cache=T}
(modelfit2 <- train(classe ~., data = trainPC, method = "gbm", verbose = F))
pred2 <- predict(modelfit2, predict(preProc, trainingTest))
confusionMatrix(pred2, trainingTest$classe)
```


```{r lda, cache=T}
(modelfit3 <- train(classe ~., data = trainPC, method = "lda"))
pred3 <- predict(modelfit3, predict(preProc, trainingTest))
confusionMatrix(pred3, trainingTest$classe)
```

```{r}
training %>%
    ggplot(aes(1:nrow(.), classe)) +
    geom_point(col = "red") +
    geom_point(aes(1:nrow(.), pred2), shape = 2, size = 3) +
    facet_wrap(~user_name, scale = "free")
```


```{r}
predict(modelfit1, predict(preProc, testing))
```
